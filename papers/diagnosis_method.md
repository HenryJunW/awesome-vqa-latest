## [Diagnosis Method](../README.md)
- Davis, Ernest,**Unanswerable {Questions} about {Images} and {Texts}**,Frontiers in Artificial Intelligence 2020 [[Paper]](http://arxiv.org/abs/2102.06793)

- Wang, Zixu and Miao, Yishu and Specia, Lucia,**Latent {Variable} {Models} for {Visual} {Question} {Answering}**,arXiv:2101.06399 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.06399)

- Zhu, Xi and Mao, Zhendong and Liu, Chunxiao and Zhang, Peng and Wang, Bin and Zhang, Yongdong,**Overcoming {Language} {Priors} with {Self}-supervised {Learning} for {Visual} {Question} {Answering}**,IJCAI 2020 [[Paper]](http://arxiv.org/abs/2012.11528)

- Winterbottom, Thomas and Xiao, Sarah and McLean, Alistair and Moubayed, Noura Al,**On {Modality} {Bias} in the {TVQA} {Dataset}**,BMVC 2020 [[Paper]](http://arxiv.org/abs/2012.10210)

- Whitehead, Spencer and Wu, Hui and Fung, Yi Ren and Ji, Heng and Feris, Rogerio and Saenko, Kate,**Learning from {Lexical} {Perturbations} for {Consistent} {Visual} {Question} {Answering}**,arXiv:2011.13406 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13406)

- Le-Ngo, Anh-Cat and Tran, Truyen and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha,**Logically {Consistent} {Loss} for {Visual} {Question} {Answering}**,arXiv:2011.10094 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.10094)

- Guo, Yangyang and Nie, Liqiang and Cheng, Zhiyong and Tian, Qi,**Loss-rescaling {VQA}: {Revisiting} {Language} {Prior} {Problem} from a {Class}-imbalance {View}**,arXiv:2010.16010 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.16010)

- Dua, Radhika and Kancheti, Sai Srinivas and Balasubramanian, Vineeth N.,**Beyond {VQA}: {Generating} {Multi}-word {Answer} and {Rationale} to {Visual} {Questions}**,arXiv:2010.11997 [cs] 2020 [[Paper]](https://arxiv.org/abs/2010.12852v1)

- Dharur, Sameer and Tendulkar, Purva and Batra, Dhruv and Parikh, Devi and Selvaraju, Ramprasaath R.,**{SOrT}-ing {VQA} {Models} : {Contrastive} {Gradient} {Learning} for {Improved} {Consistency}**,arXiv:2010.10038 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.10038)

- Huang, Hantao and Han, Tao and Han, Wei and Yap, Deep and Chiang, Cheng-Ming,**Answer-checking in {Context}: {A} {Multi}-modal {FullyAttention} {Network} for {Visual} {Question} {Answering}**,arXiv:2010.08708 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.08708)

- Kant, Yash and Moudgil, Abhinav and Batra, Dhruv and Parikh, Devi and Agrawal, Harsh,**Contrast and {Classify}: {Alternate} {Training} for {Robust} {VQA}**,arXiv:2010.06087 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.06087)

- Han, Wei and Huang, Hantao and Han, Tao,**Finding the {Evidence}: {Localization}-aware {Answer} {Prediction} for {Text} {Visual} {Question} {Answering}**,arXiv:2010.02582 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.02582)

- Gokhale, Tejas and Banerjee, Pratyay and Baral, Chitta and Yang, Yezhou,**{MUTANT}: {A} {Training} {Paradigm} for {Out}-of-{Distribution} {Generalization} in {Visual} {Question} {Answering}**,arXiv:2009.08566 [cs] 2020 [[Paper]](http://arxiv.org/abs/2009.08566)

- Do, Tuong and Nguyen, Binh X. and Tran, Huy and Tjiputra, Erman and Tran, Quang D. and Do, Thanh-Toan,**Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering**,arXiv:2009.11118 [cs] 2020 [[Paper]](http://arxiv.org/abs/2009.11118)

- Long, Yu and Tang, Pengjie and Wei, Zhihua and Gu, Jinjing and Wang, Hanli,**{RepeatPadding}: {Balancing} words and sentence length for language comprehension in visual question answering**,Information Sciences 2020 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S002002552030342X)

- Liu, Feng and Xiang, Tao and Hospedales, Timothy M. and Yang, Wankou and Sun, Changyin,**Inverse {Visual} {Question} {Answering}**,IEEE Transactions on Pattern Analysis and Machine Intelligence 2020 [[Paper]](https://ieeexplore.ieee.org/document/8528867/)

- Halbe, Shaunak, **Exploring Weaknesses of VQA Models through Attribution Driven Insights**, arXiv:2006.06637   2020   [[Paper]](http://arxiv.org/abs/2006.06637)

- Grand, Gabriel; Belinkov, Yonatan, **Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects**, arXiv:1906.08430 [cs, stat] 2019   [[Paper]](http://arxiv.org/abs/1906.08430)

- KV, Gouthaman; Mittal, Anurag, **Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder**, arXiv:2007.06198   2020   [[Paper]](http://arxiv.org/abs/2007.06198)

- Alipour, Kamran; Ray, Arijit; Lin, Xiao; Schulze, Jurgen P.; Yao, Yi; Burachas, Giedrius T., **The Impact of Explanations on AI Competency Prediction in VQA**, arXiv:2007.00900   2020   [[Paper]](http://arxiv.org/abs/2007.00900)

- Terao, Kento; Tamaki, Toru; Raytchev, Bisser; Kaneda, Kazufumi; Satoh, Shun'ichi, **Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions**, arXiv:2004.05595   2020   [[Paper]](http://arxiv.org/abs/2004.05595)

- Shrestha, Robik; Kafle, Kushal; Kanan, Christopher, **A negative case analysis of visual grounding methods for VQA**, arXiv:2004.05704   2020   [[Paper]](http://arxiv.org/abs/2004.05704)

- Abbasnejad, Ehsan; Teney, Damien; Parvaneh, Amin; Shi, Javen, **Counterfactual Vision and Language Learning**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition nan. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Abbasnejad_Counterfactual_Vision_and_Language_Learning_CVPR_2020_paper.pdf)

- Jolly, Shailza; Palacio, Sebastian; Folz, Joachim; Raue, Federico; Hees, Joern; Dengel, Andreas, **P $\approx$ NP, at least in Visual Question Answering**, arXiv:2003.11844   2020   [[Paper]](http://arxiv.org/abs/2003.11844)

- Shevchenko, Violetta; Teney, Damien; Dick, Anthony; Hengel, Anton van den, **Visual Question Answering with Prior Class Semantics**, arXiv:2005.01239   2020   [[Paper]](http://arxiv.org/abs/2005.01239)


- Kolling, Camila; Wehrmann, Jônatas; Barros, Rodrigo C., **Component Analysis for Visual Question Answering Architectures**, arXiv:2002.05104   2020   [[Paper]](http://arxiv.org/abs/2002.05104)

- van Steenkiste, Sjoerd; Locatello, Francesco; Schmidhuber, Jürgen; Bachem, Olivier, **Are Disentangled Representations Helpful for Abstract Visual Reasoning?**, Advances in Neural Information Processing Systems 2019   [[Paper]](http://arxiv.org/abs/1905.12506)

- Cao, Qingxing and Liang, Xiaodan and Li, Bailin and Lin, Liang,**Interpretable {Visual} {Question} {Answering} by {Reasoning} on {Dependency} {Trees}**,IEEE Transactions on Pattern Analysis and Machine Intelligence 2019 [[Paper]](https://ieeexplore.ieee.org/document/8847465/)

- Selvaraju, Ramprasaath R.; Lee, Stefan; Shen, Yilin; Jin, Hongxia; Ghosh, Shalini; Heck, Larry; Batra, Dhruv; Parikh, Devi, **Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded**, Proceedings of the IEEE International Conference on Computer Vision 2019   [[Paper]](http://arxiv.org/abs/1902.03751)

- Huang, Jia-Hong; Alfadly, Modar; Ghanem, Bernard; Worring, Marcel, **Assessing the Robustness of Visual Question Answering**, arXiv:1912.01452   2019   [[Paper]](http://arxiv.org/abs/1912.01452)

- Cadene, Remi; Dancette, Corentin; Ben-younes, Hedi; Cord, Matthieu; Parikh, Devi, **RUBi: Reducing Unimodal Biases in Visual Question Answering**, Advances in neural information processing systems 2019   [[Paper]](http://arxiv.org/abs/1906.10169)

- Pahuja, Vardaan; Fu, Jie; Pal, Christopher J., **Learning Sparse Mixture of Experts for Visual Question Answering**, arXiv:1909.09192 [cs, stat] 2019   [[Paper]](http://arxiv.org/abs/1909.09192)

- Kuhnle, Alexander; Xie, Huiyuan; Copestake, Ann A., **How clever is the FiLM model, and how clever can it be?**, Proceedings of the European Conference on Computer Vision (ECCV) 2018   [[Paper]](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Kuhnle_How_clever_is_the_FiLM_model_and_how_clever_can_ECCVW_2018_paper.pdf)

- Park, Dong Huk; Hendricks, Lisa Anne; Akata, Zeynep; Rohrbach, Anna; Schiele, Bernt; Darrell, Trevor; Rohrbach, Marcus, **Multimodal Explanations: Justifying Decisions and Pointing to the Evidence**, arXiv:1802.08129   2018   [[Paper]](http://arxiv.org/abs/1802.08129)

- Prabhakar, Prakruthi; Kulkarni, Nitish; Zhang, Linghao, **Question Relevance in Visual Question Answering**, arXiv:1807.08435   2018   [[Paper]](http://arxiv.org/abs/1807.08435)

- Agrawal, Aishwarya; Batra, Dhruv; Parikh, Devi; Kembhavi, Aniruddha, **Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1712.00377)



- Manjunatha, Varun; Saini, Nirat; Davis, Larry S., **Explicit Bias Discovery in Visual Question Answering Models**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1811.07789)


- Chao, Wei-Lun; Hu, Hexiang; Sha, Fei, **Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets**, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) 2018   [[Paper]](https://www.aclweb.org/anthology/N18-1040)

- Malinowski, Mateusz; Doersch, Carl, **The Visual QA Devil in the Details: The Impact of Early Fusion and Batch Norm on CLEVR**, arXiv:1809.04482   2018   [[Paper]](http://arxiv.org/abs/1809.04482)

- Ramakrishnan, Santhosh K.; Pal, Ambar; Sharma, Gaurav; Mittal, Anurag, **An Empirical Evaluation of Visual Question Answering for Novel Objects**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2017   [[Paper]](http://arxiv.org/abs/1704.02516)

- Kafle, Kushal; Yousefhussien, Mohammed; Kanan, Christopher, **Data Augmentation for Visual Question Answering**, Proceedings of the 10th International Conference on Natural Language Generation 2017   [[Paper]](https://www.aclweb.org/anthology/W17-3529)

- Qiao, Tingting; Dong, Jianfeng; Xu, Duanqing, **Exploring Human-like Attention Supervision in Visual Question Answering**, Thirty-Second AAAI Conference on Artificial Intelligence 2017   [[Paper]](http://arxiv.org/abs/1709.06308)

- Huang, Jia-Hong; Dao, Cuong Duc; Alfadly, Modar; Ghanem, Bernard, **A Novel Framework for Robustness Analysis of Visual QA Models**, Proceedings of the AAAI Conference on Artificial Intelligence 2017   [[Paper]](http://arxiv.org/abs/1711.06232)

- Selvaraju, Ramprasaath R.; Cogswell, Michael; Das, Abhishek; Vedantam, Ramakrishna; Parikh, Devi; Batra, Dhruv, **Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization**, 2017 IEEE International Conference on Computer Vision (ICCV) 2017   [[Paper]](http://ieeexplore.ieee.org/document/8237336/)

- Huang, Jia-Hong; Alfadly, Modar; Ghanem, Bernard, **Robustness Analysis of Visual QA Models by Basic Questions**, ArXiv 2017   [[Paper]](https://arxiv.org/pdf/1709.04625)

- Kafle, Kushal; Kanan, Christopher, **An Analysis of Visual Question Answering Algorithms**, Proceedings of the IEEE International Conference on Computer Vision 2017   [[Paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Kafle_An_Analysis_of_ICCV_2017_paper.pdf)

- Ray, Arijit; Christie, Gordon; Bansal, Mohit; Batra, Dhruv; Parikh, Devi, **Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions**, Proceedings of the 2016 Conference on Empirical Methods in Natural           Language Processing 2016   [[Paper]](http://aclweb.org/anthology/D16-1090)

- Agrawal, Aishwarya; Batra, Dhruv; Parikh, Devi, **Analyzing the Behavior of Visual Question Answering Models**, narXiv:1606.07356 2016   [[Paper]](http://www.researchgate.net/publication/304352594_Analyzing_the_Behavior_of_Visual_Question_Answering_Models)

- Das, Abhishek; Agrawal, Harsh; Zitnick, C. Lawrence; Parikh, Devi; Batra, Dhruv, **Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?**, Computer Vision and Image Understanding 2016   [[Paper]](http://arxiv.org/abs/1606.03556)

- Goyal, Yash; Mohapatra, Akrit; Parikh, Devi; Batra, Dhruv, **Towards Transparent AI Systems: Interpreting Visual Question Answering Models**, arXiv:1608.08974   2016   [[Paper]](http://arxiv.org/abs/1608.08974)

- Jabri, Allan; Joulin, Armand; van der Maaten, Laurens, **Revisiting Visual Question Answering Baselines**, European conference on computer vision 2016   [[Paper]](https://arxiv.org/abs/1606.08390v2)

- Zhang, Peng; Goyal, Yash; Summers-Stay, Douglas; Batra, Dhruv; Parikh, Devi, **Yin and Yang: Balancing and Answering Binary Visual Questions**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2015   [[Paper]](http://arxiv.org/abs/1511.05099)

- Wu, Qi; Shen, Chunhua; Liu, Lingqiao; Dick, Anthony; Hengel, Anton van den, **What value do explicit high level concepts have in vision to language problems?**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1506.01144)

- Agarwal, Vedika; Shetty, Rakshith; Fritz, Mario, **Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Agarwal_Towards_Causal_VQA_Revealing_and_Reducing_Spurious_Correlations_by_Invariant_CVPR_2020_paper.pdf)

- Selvaraju, Ramprasaath R; Tendulkar, Purva; Parikh, Devi; Horvitz, Eric; Ribeiro, Marco Tulio; Nushi, Besmira; Kamar, Ece, **SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Selvaraju_SQuINTing_at_VQA_Models_Introspecting_VQA_Models_With_Sub-Questions_CVPR_2020_paper.pdf)
