# Awesome Visual Question Answering [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)


A constant updating reading list of resources dedicated to Visual Question Answering.  

Welcome to PR :smile:.

## Contents
- [Papers](#papers)
    - [Review Papers](#review-papers)
    - [Datasets](#datasets)
    - [Joint Embedding](#joint-embedding)
    - [Attention-Based](#attention-based)
    - [Knowledge-Based](#knowledge-based)
    - [Memory Network](#memory-network)
    - [Modular Network](#modular-network)
    - [Graph and Nerual-symbolic](#graph-and-neural-symbolic)
    - [Representation](#representation)
    - [Visual Reasoning](#visual-reasoning)
    - [Diagnosis Method](#diagnosis-method)
    - [Others](#others)


### Papers
#### Review Papers
- Uppal, Shagun and Bhagat, Sarthak and Hazarika, Devamanyu and Majumdar, Navonil and Poria, Soujanya and Zimmermann, Roger and Zadeh, Amir,**Multimodal {Research} in {Vision} and {Language}: {A} {Review} of {Current} and {Emerging} {Trends}**,arxiv 2020 [[Paper]](https://arxiv.org/abs/2010.09522v2)
 
- Zhang, Dongxiang and Cao, Rui and Wu, Sai,**Information fusion in visual question answering**,Information Fusion 2019 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S1566253518308893)

- Mogadala, Aditya; Kalimuthu, Marimuthu; Klakow, Dietrich, **Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods**, arXiv:1907.09358   2019   [[Paper]](http://arxiv.org/abs/1907.09358)

- Gupta, Akshay Kumar, **Survey of Visual Question Answering: Datasets and Techniques**, arXiv:1705.03865   2017   [[Paper]](http://arxiv.org/abs/1705.03865)

- Kafle, Kushal; Kanan, Christopher, **Visual Question Answering: Datasets, Algorithms, and Future Challenges**, Computer Vision and Image Understanding 2017   [[Paper]](http://arxiv.org/abs/1610.01465)

- Wu, Qi; Teney, Damien; Wang, Peng; Shen, Chunhua; Dick, Anthony; Hengel, Anton van den, **Visual Question Answering: A Survey of Methods and Datasets**, Computer Vision and Image Understanding 2016   [[Paper]](http://arxiv.org/abs/1607.05910)

#### Datasets
- Chen, Zhanwen and Li, Shiyao and Rashedi, Roxanne and Zi, Xiaoman and Elrod-Erickson, Morgan and Hollis, Bryan and Maliakal, Angela and Shen, Xinyu and Zhao, Simeng and Kunda, Maithilee,**Characterizing {Datasets} for {Social} {Visual} {Question} {Answering}, and the {New} {TinySocial} {Dataset}**,arXiv:2010.11997 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.11997)

- He, Xuehai and Cai, Zhuo and Wei, Wenlan and Zhang, Yichen and Mou, Luntian and Xing, Eric and Xie, Pengtao,**Pathological {Visual} {Question} {Answering}**,arXiv:2010.11997 [cs] 2020 [[Paper]](https://arxiv.org/abs/2010.12435v1)

- Garcia, Noa and Ye, Chentao and Liu, Zihua and Hu, Qingtao and Otani, Mayu and Chu, Chenhui and Nakashima, Yuta and Mitamura, Teruko,**A {Dataset} and {Baselines} for {Visual} {Question} {Answering} on {Art}**,arXiv:2008.12520 2020 [[Paper]](http://arxiv.org/abs/2008.12520)

- Mathew, Minesh and Tito, Ruben and Karatzas, Dimosthenis and Manmatha, R and Jawahar, CV, **Document Visual Question Answering Challenge 2020**, arXiv:2008.08899 2020 [[Paper]](http://arxiv.org/abs/2008.08899)
  
- Chou, Shih-Han; Chao, Wei-Lun; Lai, Wei-Sheng; Sun, Min; Yang, Ming-Hsuan, **Visual Question Answering on 360{\deg} Images**, The IEEE Winter Conference on Applications of Computer Vision 2020   [[Paper]](http://arxiv.org/abs/2001.03339)

- Mathew, Minesh; Karatzas, Dimosthenis; Manmatha, R.; Jawahar, C. V., **DocVQA: A Dataset for VQA on Document Images**, nan 2020   [[Paper]](https://arxiv.org/abs/2007.00398v1)

- Sampat, Shailaja; Yang, Yezhou; Baral, Chitta, **Diverse Visuo-Lingustic Question Answering (DVLQA) Challenge**, arXiv:2005.00330   2020   [[Paper]](http://arxiv.org/abs/2005.00330)

- Lobry, Sylvain; Marcos, Diego; Murray, Jesse; Tuia, Devis, **RSVQA: Visual Question Answering for Remote Sensing Data**, IEEE Transactions on Geoscience and Remote Sensing 2020   [[Paper]](http://arxiv.org/abs/2003.07333)

- Bongini, Pietro; Becattini, Federico; Bagdanov, Andrew D.; Del Bimbo, Alberto, **Visual Question Answering for Cultural Heritage**, arXiv:2003.09853   2020   [[Paper]](http://arxiv.org/abs/2003.09853)

- Hudson, Drew A.; Manning, Christopher D., **GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019   [[Paper]](http://arxiv.org/abs/1902.09506)

- Singh, Amanpreet; Natarajan, Vivek; Shah, Meet; Jiang, Yu; Chen, Xinlei; Batra, Dhruv; Parikh, Devi; Rohrbach, Marcus, **Towards VQA Models That Can Read**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019   [[Paper]](http://arxiv.org/abs/1904.08920)

- Goyal, Yash; Khot, Tejas; Agrawal, Aishwarya; Summers-Stay, Douglas; Batra, Dhruv; Parikh, Devi, **Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering**, International Journal of Computer Vision 2019   [[Paper]](http://link.springer.com/10.1007/s11263-018-1116-0)

- Gao, Difei; Wang, Ruiping; Shan, Shiguang; Chen, Xilin, **From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense**, arXiv:1908.02962 2019   [[Paper]](https://arxiv.org/abs/1908.02962v2)

- Marino, Kenneth; Rastegari, Mohammad; Farhadi, Ali; Mottaghi, Roozbeh, **OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019   [[Paper]](http://arxiv.org/abs/1906.00067)

- Shah, Sanket; Mishra, Anand; Yadati, Naganand; Talukdar, Partha Pratim, **KVQA: Knowledge-Aware Visual Question Answering**, Proceedings of the AAAI Conference on Artificial Intelligence 2019   [[Paper]](https://144.208.67.177/ojs/index.php/AAAI/article/view/4915)

- Gurari, Danna; Li, Qing; Stangl, Abigale J.; Guo, Anhong; Lin, Chi; Grauman, Kristen; Luo, Jiebo; Bigham, Jeffrey P., **VizWiz Grand Challenge: Answering Visual Questions from Blind People**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1802.08218)

- Yagcioglu, Semih; Erdem, Aykut; Erdem, Erkut; Ikizler-Cinbis, Nazli, **RecipeQA: A Challenge Dataset for Multimodal Comprehension of Cooking Recipes**, arXiv:1809.00812   2018   [[Paper]](http://arxiv.org/abs/1809.00812)

- Zhang, Yan; Hare, Jonathon; Pr√ºgel-Bennett, Adam, **Learning to Count Objects in Natural Images for Visual Question Answering**, arXiv:1802.05766 2018   [[Paper]](https://arxiv.org/abs/1802.05766v1)

- Zellers, Rowan; Bisk, Yonatan; Farhadi, Ali; Choi, Yejin, **From Recognition to Cognition: Visual Commonsense Reasoning**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1811.10830)

- Acharya, Manoj; Kafle, Kushal; Kanan, Christopher, **TallyQA: Answering Complex Counting Questions**, Proceedings of the AAAI Conference on Artificial Intelligence 2018   [[Paper]](https://arxiv.org/abs/1810.12440v2)

- Kahou, Samira Ebrahimi; Michalski, Vincent; Atkinson, Adam; Kadar, Akos; Trischler, Adam; Bengio, Yoshua, **FigureQA: An Annotated Figure Dataset for Visual Reasoning**, arXiv:1710.07300   2018   [[Paper]](http://arxiv.org/abs/1710.07300)

- Kafle, Kushal; Cohen, Scott; Price, Brian L.; Kanan, Christopher, **DVQA: Understanding Data Visualizations via Question Answering**, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](https://openaccess.thecvf.com/content_cvpr_2018/html/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.html)

- Agrawal, Aishwarya; Kembhavi, Aniruddha; Batra, Dhruv; Parikh, Devi, **C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset**, arXiv:1704.08243 2017   [[Paper]](https://arxiv.org/abs/1704.08243v1)

- Chattopadhyay, Prithvijit and Vedantam, Ramakrishna and Selvaraju, Ramprasaath R and Batra, Dhruv and Parikh, Devi,**Counting everyday objects in everyday scenes**,Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2017 [[Paper]](https://arxiv.org/abs/1604.03505v1)

- Wang, Peng; Wu, Qi; Shen, Chunhua; Hengel, Anton van den; Dick, Anthony, **FVQA: Fact-based Visual Question Answering**, IEEE transactions on pattern analysis and machine intelligence 2016   [[Paper]](http://arxiv.org/abs/1606.05433)

- Johnson, Justin; Hariharan, Bharath; van der Maaten, Laurens; Fei-Fei, Li; Zitnick, C. Lawrence; Girshick, Ross, **CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2016   [[Paper]](http://arxiv.org/abs/1612.06890)

- Kembhavi, Aniruddha; Salvato, Mike; Kolve, Eric; Seo, Minjoon; Hajishirzi, Hannaneh; Farhadi, Ali, **A Diagram Is Worth A Dozen Images**, European Conference on Computer Vision 2016   [[Paper]](http://arxiv.org/abs/1603.07396)

- Krishna, Ranjay; Zhu, Yuke; Groth, Oliver; Johnson, Justin; Hata, Kenji; Kravitz, Joshua; Chen, Stephanie; Kalantidis, Yannis; Li, Li-Jia; Shamma, David A.; Bernstein, Michael S.; Li, Fei-Fei, **Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations**, International journal of computer vision 2016   [[Paper]](http://arxiv.org/abs/1602.07332)

- Gao, Haoyuan; Mao, Junhua; Zhou, Jie; Huang, Zhiheng; Wang, Lei; Xu, Wei, **Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2015   [[Paper]](http://arxiv.org/abs/1505.05612)

- Ren, Mengye; Kiros, Ryan; Zemel, Richard, **Exploring Models and Data for Image Question Answering**, Advances in neural information processing systems 2015   [[Paper]](http://arxiv.org/abs/1505.02074)

- Zhu, Yuke; Groth, Oliver; Bernstein, Michael; Fei-Fei, Li, **Visual7W: Grounded Question Answering in Images**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1511.03416)

- Agrawal, Aishwarya; Lu, Jiasen; Antol, Stanislaw; Mitchell, Margaret; Zitnick, C. Lawrence; Batra, Dhruv; Parikh, Devi, **VQA: Visual Question Answering**, Proceedings of the IEEE international conference on computer vision 2015   [[Paper]](http://arxiv.org/abs/1505.00468)

- Yu, Licheng; Park, Eunbyung; Berg, Alexander C.; Berg, Tamara L., **Visual Madlibs: Fill in the blank Image Generation and Question Answering**, arXiv:1506.00278   2015   [[Paper]](http://arxiv.org/abs/1506.00278)

- Malinowski, Mateusz; Fritz, Mario, **A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input**, Advances in neural information processing systems 2014   [[Paper]](http://arxiv.org/abs/1410.0210)


#### Joint Embedding
- Zhang, Weifeng and Yu, Jing and Hu, Hua and Hu, Haiyang and Qin, Zengchang,**Multimodal feature fusion by relational reasoning and attention for visual question answering**,Information Fusion 2020 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S1566253518308248)

- Zheng, Chen; Guo, Quan; Kordjamshidi, Parisa, **Cross-Modality Relevance for Reasoning on Language and Vision**, arXiv:2005.06035   2020   [[Paper]](http://arxiv.org/abs/2005.06035)

- Fang, Zhiwei; Liu, Jing; Liu, Xueliang; Tang, Qu; Li, Yonghong; Lu, Hanqing, **BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering**, ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) 2019   [[Paper]](https://dl.acm.org/doi/abs/10.1145/3282469)

- Liu, Bei; Huang, Zhicheng; Zeng, Zhaoyang; Chen, Zheyu; Fu, Jianlong, **Learning Rich Image Region Representation for Visual Question Answering**, arXiv:1910.13077 2019   [[Paper]](https://arxiv.org/abs/1910.13077v1)

- Gao, Peng; Li, Hongsheng; Li, Shuang; Lu, Pan; Li, Yikang; Hoi, Steven C. H.; Wang, Xiaogang, **Question-Guided Hybrid Convolution for Visual Question Answering**, Proceedings of the European Conference on Computer Vision (ECCV) 2018   [[Paper]](http://openaccess.thecvf.com/content_ECCV_2018/html/gao_peng_Question-Guided_Hybrid_Convolution_ECCV_2018_paper.html)

- Yu, Zhou; Yu, Jun; Xiang, Chenchao; Fan, Jianping; Tao, Dacheng, **Beyond Bilinear: Generalized Multimodal Factorized High-order Pooling for Visual Question Answering**, IEEE Transactions on Neural Networks and Learning Systems 2018   [[Paper]](http://arxiv.org/abs/1708.03619)

- Yu, Zhou; Yu, Jun; Fan, Jianping; Tao, Dacheng, **Multi-modal Factorized Bilinear Pooling with Co-Attention Learning for Visual Question Answering**, Proceedings of the IEEE international conference on computer vision 2017   [[Paper]](http://arxiv.org/abs/1708.01471)


- Kim, Jin-Hwa; On, Kyoung-Woon; Lim, Woosang; Kim, Jeonghee; Ha, Jung-Woo; Zhang, Byoung-Tak, **Hadamard Product for Low-rank Bilinear Pooling**, arXiv:1610.04325   2017   [[Paper]](http://arxiv.org/abs/1610.04325)

- Ben-younes, Hedi; Cadene, R√©mi; Cord, Matthieu; Thome, Nicolas, **MUTAN: Multimodal Tucker Fusion for Visual Question Answering**, Proceedings of the IEEE international conference on computer vision 2017   [[Paper]](http://arxiv.org/abs/1705.06676)

- Ilievski, Ilija; Feng, Jiashi, **Multimodal Learning and Reasoning for Visual Question Answering**, Advances in Neural Information Processing Systems 30 2017   [[Paper]](http://papers.nips.cc/paper/6658-multimodal-learning-and-reasoning-for-visual-question-answering.pdf)

- Saito, Kuniaki; Shin, Andrew; Ushiku, Yoshitaka; Harada, Tatsuya, **DualNet: Domain-Invariant Network for Visual Question Answering**, 2017 IEEE International Conference on Multimedia and Expo (ICME) 2016   [[Paper]](http://arxiv.org/abs/1606.06108)

- Noh, Hyeonwoo; Han, Bohyung, **Training Recurrent Answering Units with Joint Loss Minimization for VQA**, arXiv:1606.03647   2016   [[Paper]](http://arxiv.org/abs/1606.03647)

- Kim, Jin-Hwa; Lee, Sang-Woo; Kwak, Dong-Hyun; Heo, Min-Oh; Kim, Jeonghee; Ha, Jung-Woo; Zhang, Byoung-Tak, **Multimodal Residual Learning for Visual QA**, Advances in neural information processing systems 2016   [[Paper]](http://arxiv.org/abs/1606.01455)

- Fukui, Akira; Park, Dong Huk; Yang, Daylen; Rohrbach, Anna; Darrell, Trevor; Rohrbach, Marcus, **Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding**, arXiv:1606.01847   2016   [[Paper]](http://arxiv.org/abs/1606.01847)

- Ma, Lin; Lu, Zhengdong; Li, Hang, **Learning to Answer Questions From Image Using Convolutional Neural Network**, Thirtieth AAAI Conference on Artificial Intelligence 2015   [[Paper]](http://arxiv.org/abs/1506.00333)

- Zhou, Bolei; Tian, Yuandong; Sukhbaatar, Sainbayar; Szlam, Arthur; Fergus, Rob, **Simple Baseline for Visual Question Answering**, arXiv:1512.02167   2015   [[Paper]](http://arxiv.org/abs/1512.02167)

- Malinowski, Mateusz and Rohrbach, Marcus and Fritz, Mario, **Ask your neurons: A neural-based approach to answering questions about images**, Proceedings of the IEEE international conference on computer vision 2015 [[Paper]](http://arxiv.org/abs/1505.01121)


#### Attention-Based 
- Rahman, Tanzila and Chou, Shih-Han and Sigal, Leonid and Carenini, Giuseppe,**An {Improved} {Attention} for {Visual} {Question} {Answering}**,arXiv:2011.02164 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.02164)

- Farazi, Moshiur and Khan, Salman and Barnes, Nick,**Attention {Guided} {Semantic} {Relationship} {Parsing} for {Visual} {Question} {Answering}**,arXiv:2010.01725 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.01725)

- Liu, Yun and Zhang, Xiaoming and Huang, Feiran and Cheng, Lei and Li, Zhoujun,**Adversarial {Learning} {With} {Multi}-{Modal} {Attention} for {Visual} {Question} {Answering}**,IEEE Transactions on Neural Networks and Learning Systems 2020 [[Paper]](https://ieeexplore.ieee.org/document/9174895/)

- Lee, Doyup and Cheon, Yeongjae and Han, Wook-Shin,**Regularizing {Attention} {Networks} for {Anomaly} {Detection} in {Visual} {Question} {Answering}**,arXiv:2009.10054 [cs] 2020 [[Paper]](http://arxiv.org/abs/2009.10054)

- Gao, Lianli and Cao, Liangfu and Xu, Xing and Shao, Jie and Song, Jingkuan,**Question-{Led} object attention for visual question answering**,Neurocomputing 2020 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S0925231219304163)

- KV, Gouthaman and Nambiar, Athira and Srinivas, Kancheti Sai and Mittal, Anurag,**Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks**,arXiv preprint arXiv:2008.08012 2020 [[Paper]](http://arxiv.org/abs/2008.08012)

- Stefanini, Matteo; Cornia, Marcella; Baraldi, Lorenzo; Cucchiara, Rita, **A Novel Attention-based Aggregation Function to Combine Vision and Language**, arXiv:2004.13073   2020   [[Paper]](http://arxiv.org/abs/2004.13073)

- G√≥mez, Llu√≠s; Biten, Ali Furkan; Tito, Rub√®n; Mafla, Andr√©s; Karatzas, Dimosthenis, **Multimodal grid features and cell pointers for Scene Text Visual Question Answering**, arXiv:2006.00923   2020   [[Paper]](http://arxiv.org/abs/2006.00923)

- Gao, Chenyu; Zhu, Qi; Wang, Peng; Li, Hui; Liu, Yuliang; Hengel, Anton van den; Wu, Qi, **Structured Multimodal Attentions for TextVQA**, arXiv:2006.00753   2020   [[Paper]](http://arxiv.org/abs/2006.00753)

- Jiang, Huaizu; Misra, Ishan; Rohrbach, Marcus; Learned-Miller, Erik; Chen, Xinlei, **In Defense of Grid Features for Visual Question Answering**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://arxiv.org/abs/2001.03615)

- Yang, Chao; Jiang, Mengqi; Jiang, Bin; Zhou, Weixin; Li, Keqin, **Co-Attention Network With Question Type for Visual Question Answering**, IEEE Access 2019   [[Paper]](https://ieeexplore.ieee.org/abstract/document/8676009/)

- Yu, Zhou; Yu, Jun; Cui, Yuhao; Tao, Dacheng; Tian, Qi, **Deep Modular Co-Attention Networks for Visual Question Answering**, Proceedings of the IEEE conference on computer vision and pattern recognition 2019   [[Paper]](http://arxiv.org/abs/1906.10770)

- Hong, Jongkwang and Fu, Jianlong and Uh, Youngjung and Mei, Tao and Byun, Hyeran,**Exploiting hierarchical visual features for visual question answering**,Neurocomputing 2019 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S0925231219303753)

- Peng, Liang and Yang, Yang and Bin, Yi and Xie, Ning and Shen, Fumin and Ji, Yanli and Xu, Xing,**Word-to-region attention network for visual question answering**,Multimedia Tools and Applications 2019 [[Paper]](https://doi.org/10.1007/s11042-018-6389-3)

- Gao, Peng and Jiang, Zhengkai and You, Haoxuan and Lu, Pan and Hoi, Steven CH and Wang, Xiaogang and Li, Hongsheng,**Dynamic fusion with intra-and inter-modality attention flow for visual question answering**,Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019 [[Paper]](http://arxiv.org/abs/1812.05252)

- Zhang, Yundong; Niebles, Juan Carlos; Soto, Alvaro, **Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining**, 2019 IEEE Winter Conference on Applications of Computer Vision (WACV) 2018   [[Paper]](http://arxiv.org/abs/1808.00265)

- Anderson, Peter; He, Xiaodong; Buehler, Chris; Teney, Damien; Johnson, Mark; Gould, Stephen; Zhang, Lei, **Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering**, Proceedings of the IEEE conference on computer vision and pattern recognition 2018   [[Paper]](http://arxiv.org/abs/1707.07998)

- Lioutas, Vasileios; Passalis, Nikolaos; Tefas, Anastasios, **Visual Question Answering using Explicit Visual Attention**, 2018 IEEE International Symposium on Circuits and Systems (ISCAS) 2018   [[Paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8676009)

- Farazi, Moshiur R.; Khan, Salman H., **Reciprocal Attention Fusion for Visual Question Answering**, arXiv:1805.04247   2018   [[Paper]](http://arxiv.org/abs/1805.04247)

- Jiang, Yu; Natarajan, Vivek; Chen, Xinlei; Rohrbach, Marcus; Batra, Dhruv; Parikh, Devi, **Pythia v0.1: the Winning Entry to the VQA Challenge 2018**, arXiv:1807.09956   2018   [[Paper]](http://arxiv.org/abs/1807.09956)

- Liang, Junwei; Jiang, Lu; Cao, Liangliang; Li, Li-Jia; Hauptmann, Alexander, **Focal Visual-Text Attention for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](https://arxiv.org/abs/1806.01873v2)

- Osman, Ahmed; Samek, Wojciech, **DRAU: Dual Recurrent Attention Units for Visual Question Answering**, Computer Vision and Image Understanding 2018   [[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S1077314219300761)

- Lin, Yuetan; Pang, Zhangyang; Wang, Donghui; Zhuang, Yueting, **Feature Enhancement in Attention for Visual Question Answering**, IJCAI 2018   [[Paper]](https://pdfs.semanticscholar.org/f15a/d07b9f6686bc72c45bf781c91f8eeb035899.pdf)

- Lu, Pan; Ji, Lei; Zhang, Wei; Duan, Nan; Zhou, Ming; Wang, Jianyong, **R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering**, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining 2018   [[Paper]](https://dl.acm.org/doi/abs/10.1145/3219819.3220036)

- Bai, Yalong; Fu, Jianlong; Zhao, Tiejun; Mei, Tao, **Deep Attention Neural Tensor Network for Visual Question Answering**, Proceedings of the European Conference on Computer Vision (ECCV) 2018   [[Paper]](http://openaccess.thecvf.com/content_ECCV_2018/html/Yalong_Bai_Deep_Attention_Neural_ECCV_2018_paper.html)

- Nguyen, Duy-Kien; Okatani, Takayuki, **Improved Fusion of Visual and Language Representations by Dense Symmetric Co-Attention for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1804.00775)

- Schwartz, Idan; Schwing, Alexander G.; Hazan, Tamir, **High-Order Attention Models for Visual Question Answering**, Advances in Neural Information Processing Systems 2017   [[Paper]](http://arxiv.org/abs/1711.04323)

- Meng, Chenyue; Wang, Yixin; Zhang, Shutong, **Image-Question-Linguistic Co-Attention for Visual Question Answering**, None 2017   [[Paper]](https://pdfs.semanticscholar.org/433c/16d0be2caa7bd5672282bea1368da087f824.pdf)

- Yu, D.; Fu, J.; Mei, T.; Rui, Y., **Multi-level Attention Networks for Visual Question Answering**, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017   [[Paper]](https://openaccess.thecvf.com/content_cvpr_2017/html/Yu_Multi-Level_Attention_Networks_CVPR_2017_paper.html)

- Zhu, Chen; Zhao, Yanpeng; Huang, Shuaiyi; Tu, Kewei; Ma, Yi, **Structured Attentions for Visual Question Answering**, Proceedings of the IEEE International Conference on Computer Vision 2017   [[Paper]](http://arxiv.org/abs/1708.02071)

- Wang, Peng; Wu, Qi; Shen, Chunhua; Hengel, Anton van den, **The VQA-Machine: Learning How to Use Existing Vision Algorithms to Answer New Questions**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2016   [[Paper]](http://arxiv.org/abs/1612.05386)

- Nam, Hyeonseob; Ha, Jung-Woo; Kim, Jeonghee, **Dual Attention Networks for Multimodal Reasoning and Matching**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2016   [[Paper]](http://arxiv.org/abs/1611.00471)

- Chen, Kan; Wang, Jiang; Chen, Liang-Chieh; Gao, Haoyuan; Xu, Wei; Nevatia, Ram, **ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering**, arXiv:1511.05960   2015   [[Paper]](http://arxiv.org/abs/1511.05960)

- Kazemi, Vahid; Elqursh, Ali, **Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering**, arXiv:1704.03162   2017   [[Paper]](http://arxiv.org/abs/1704.03162)

- Lu, Jiasen; Yang, Jianwei; Batra, Dhruv; Parikh, Devi, **Hierarchical Question-Image Co-Attention for Visual Question Answering**, Advances in neural information processing systems 2016   [[Paper]](http://arxiv.org/abs/1606.00061)

- Ilievski, Ilija; Yan, Shuicheng; Feng, Jiashi, **A Focused Dynamic Attention Model for Visual Question Answering**, arXiv:1604.01485   2016   [[Paper]](http://arxiv.org/abs/1604.01485)

- Shih, Kevin J.; Singh, Saurabh; Hoiem, Derek, **Where To Look: Focus Regions for Visual Question Answering**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1511.07394)

- Xu, Huijuan; Saenko, Kate, **Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering**, European Conference on Computer Vision 2015   [[Paper]](http://arxiv.org/abs/1511.05234)

- Yang, Zichao; He, Xiaodong; Gao, Jianfeng; Deng, Li; Smola, Alex, **Stacked Attention Networks for Image Question Answering**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1511.02274)

#### Knowledge-Based
- Marino, Kenneth and Chen, Xinlei and Parikh, Devi and Gupta, Abhinav and Rohrbach, Marcus,**{KRISP}: {Integrating} {Implicit} and {Symbolic} {Knowledge} for {Open}-{Domain} {Knowledge}-{Based} {VQA}**,arXiv:2012.11014 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11014)

- Cao, Qingxing and Li, Bailin and Liang, Xiaodan and Wang, Keze and Lin, Liang,**Knowledge-{Routed} {Visual} {Question} {Reasoning}: {Challenges} for {Deep} {Representation} {Embedding}**,arXiv:2012.07192 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.07192)

- Song, Dandan and Ma, Siyi and Sun, Zhanchen and Yang, Sicheng and Liao, Lejian,**{KVL}-{BERT}: {Knowledge} {Enhanced} {Visual}-and-{Linguistic} {BERT} for {Visual} {Commonsense} {Reasoning}**,arXiv:2012.07000 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.07000)

- Yu, Jing and Zhu, Zihao and Wang, Yujing and Zhang, Weifeng and Hu, Yue and Tan, Jianlong,**Cross-modal knowledge reasoning for knowledge-based visual question answering**,Pattern Recognition 2020 [[Paper]](http://arxiv.org/abs/2008.12520)

- Zhu, Zihao; Yu, Jing; Wang, Yujing; Sun, Yajing; Hu, Yue; Wu, Qi, **Mucko: Multi-Layer Cross-Modal Knowledge Reasoning for Fact-based Visual Question Answering**, arXiv:2006.09073   2020   [[Paper]](http://arxiv.org/abs/2006.09073)

- Cao, Qingxing; Li, Bailin; Liang, Xiaodan; Lin, Liang, **Explainable High-order Visual Question Reasoning: A New Benchmark and Knowledge-routed Network**, arXiv:1909.10128 2019   [[Paper]](https://arxiv.org/abs/1909.10128v1)

- Farazi, Moshiur R.; Khan, Salman H.; Barnes, Nick, **From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts**, arXiv:1811.12772   2018   [[Paper]](http://arxiv.org/abs/1811.12772)

- Narasimhan, Medhini; Schwing, Alexander G., **Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering**, Proceedings of the European conference on computer vision (ECCV) 2018   [[Paper]](http://arxiv.org/abs/1809.01124)


- Zhu, Yuke; Lim, Joseph J.; Fei-Fei, Li, **Knowledge Acquisition for Visual Question Answering via Iterative Querying**, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2017   [[Paper]](http://ieeexplore.ieee.org/document/8100134/)

- Wu, Qi; Shen, Chunhua; Hengel, Anton van den; Wang, Peng; Dick, Anthony, **Image Captioning and Visual Question Answering Based on Attributes and External Knowledge**, IEEE transactions on pattern analysis and machine intelligence 2016   [[Paper]](http://arxiv.org/abs/1603.02814)

- Wang, Peng; Wu, Qi; Shen, Chunhua; Hengel, Anton van den; Dick, Anthony, **Explicit Knowledge-based Reasoning for Visual Question Answering**, arXiv:1511.02570   2015   [[Paper]](http://arxiv.org/abs/1511.02570)

- Wu, Qi; Wang, Peng; Shen, Chunhua; Dick, Anthony; Hengel, Anton van den, **Ask Me Anything: Free-form Visual Question Answering Based on Knowledge from External Sources**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1511.06973)

- Zhu, Yuke; Zhang, Ce; R√©, Christopher; Fei-Fei, Li, **Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries**, arXiv:1507.05670   2015   [[Paper]](http://arxiv.org/abs/1507.05670)

#### Memory-Based
- Su, Zhou; Zhu, Chen; Dong, Yinpeng; Cai, Dongqi; Chen, Yurong; Li, Jianguo, **Learning Visual Knowledge Memory Networks for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/html/Su_Learning_Visual_Knowledge_CVPR_2018_paper.html)


- Ma, Chao; Shen, Chunhua; Dick, Anthony; Wu, Qi; Wang, Peng; Hengel, Anton van den; Reid, Ian, **Visual Question Answering with Memory-Augmented Networks**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1707.04968)

- Yang, Guangyu Robert and Ganichev, Igor and Wang, Xiao-Jing and Shlens, Jonathon and Sussillo, David,**A dataset and architecture for visual reasoning with a working memory**,European Conference on Computer Vision 2018 [[Paper]](https://link.springer.com/chapter/10.1007/978-3-030-01249-6_44)

- Li, Guohao; Su, Hang; Zhu, Wenwu, **Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks**, arXiv:1712.00733   2017   [[Paper]](http://arxiv.org/abs/1712.00733)

- Xiong, Caiming; Merity, Stephen; Socher, Richard, **Dynamic Memory Networks for Visual and Textual Question Answering**, International conference on machine learning 2016   [[Paper]](http://arxiv.org/abs/1603.01417)

- Jiang, Aiwen; Wang, Fang; Porikli, Fatih; Li, Yi, **Compositional Memory for Visual Question Answering**, arXiv:1511.05676   2015   [[Paper]](http://arxiv.org/abs/1511.05676)

#### Modular Network 
- Tang, Ruixue and Ma, Chao,**Interpretable {Neural} {Computation} for {Real}-{World} {Compositional} {Visual} {Question} {Answering}**,arXiv:2010.04913 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.04913)

- Sur, Chiranjib, **Self-Segregating and Coordinated-Segregating Transformer for Focused Deep Multi-Modular Network for Visual Question Answering**, arXiv:2006.14264 2020   [[Paper]](https://arxiv.org/abs/2006.14264v1)

- Kim, Seung Wook; Tapaswi, Makarand; Fidler, Sanja, **Visual Reasoning by Progressive Module Networks**, arXiv:1806.02453   2018   [[Paper]](http://arxiv.org/abs/1806.02453)

- Hudson, Drew A.; Manning, Christopher D., **Compositional Attention Networks for Machine Reasoning**, arXiv:1803.03067   2018   [[Paper]](http://arxiv.org/abs/1803.03067)

- Andreas, Jacob; Rohrbach, Marcus; Darrell, Trevor; Klein, Dan, **Learning to Compose Neural Networks for Question Answering**, arXiv:1601.01705   2016   [[Paper]](http://arxiv.org/abs/1601.01705)

- Andreas, Jacob; Rohrbach, Marcus; Darrell, Trevor; Klein, Dan, **Neural Module Networks**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1511.02799)

#### Graph and Neural-Symbolic
- Liang, Weixin and Niu, Feiyang and Reganti, Aishwarya and Thattai, Govind and Tur, Gokhan,**{LRTA}: {A} {Transparent} {Neural}-{Symbolic} {Reasoning} {Framework} with {Modular} {Supervision} for {Visual} {Question} {Answering}**,arXiv:2011.10731 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.10731)

- Zhu, Xi and Mao, Zhendong and Chen, Zhineng and Li, Yangyang and Wang, Zhaohui and Wang, Bin,**Object-difference drived graph convolutional networks for visual question answering**,Multimedia Tools and Applications 2020 [[Paper]](http://link.springer.com/10.1007/s11042-020-08790-0)

- Guo, Dalu; Xu, Chang; Tao, Dacheng, **Bilinear Graph Networks for Visual Question Answering**, arXiv:1907.09815   2020   [[Paper]](http://arxiv.org/abs/1907.09815)

- Hildebrandt, Marcel; Li, Hang; Koner, Rajat; Tresp, Volker; G√ºnnemann, Stephan, **Scene Graph Reasoning for Visual Question Answering**, arXiv:2007.01072 [cs, stat] 2020   [[Paper]](http://arxiv.org/abs/2007.01072)

- Zhu, Xi; Mao, Zhendong; Chen, Zhineng; Li, Yangyang; Wang, Zhaohui; Wang, Bin, **Object-difference drived graph convolutional networks for visual question answering**, Multimedia Tools and Applications 2020   [[Paper]](http://www.liyangyang.com/wp-content/uploads/2020/05/MTA20-QA-YangyangLi.pdf)

- Cao, Qingxing; Liang, Xiaodan; Wang, Keze; Lin, Liang, **Linguistically Driven Graph Capsule Network for Visual Question Reasoning**, arXiv:2003.10065   2020   [[Paper]](http://arxiv.org/abs/2003.10065)


- Zhang, Cuicui; Chao, Wei-Lun; Xuan, Dong, **An Empirical Study on Leveraging Scene Graphs for Visual Question Answering**, ArXiv 2019   [[Paper]](https://arxiv.org/pdf/1907.12133)

- Mao, Jiayuan and Gan, Chuang and Kohli, Pushmeet and Tenenbaum, Joshua B and Wu, Jiajun,**The neuro-symbolic concept learner: Interpreting scenes, words, and sentences from natural supervision**,arXiv preprint arXiv:1904.12584 2019 [[Paper]](https://arxiv.org/abs/1803.06092)

- Li, Linjie; Gan, Zhe; Cheng, Yu; Liu, Jingjing, **Relation-Aware Graph Attention Network for Visual Question Answering**, Proceedings of the IEEE International Conference on Computer Vision 2019   [[Paper]](https://arxiv.org/abs/1903.12314v3)

- Hudson, Drew A.; Manning, Christopher D., **Learning by Abstraction: The Neural State Machine**, Advances in Neural Information Processing Systems 2019   [[Paper]](http://arxiv.org/abs/1907.03950)
 
- Khademi, Mahmoud, **Multimodal Neural Graph Memory Networks for Visual Question Answering**, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics 2019   [[Paper]](https://grlearning.github.io/papers/32.pdf)

- Norcliffe-Brown, Will; Vafeias, Stathis; Parisot, Sarah, **Learning Conditioned Graph Structures for Interpretable Visual Question Answering**, Advances in neural information processing systems 2018   [[Paper]](http://papers.nips.cc/paper/8054-learning-conditioned-graph-structures-for-interpretable-visual-question-answering.pdf)

- Yi, Kexin; Wu, Jiajun; Gan, Chuang; Torralba, Antonio; Kohli, Pushmeet; Tenenbaum, Joshua B., **Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding**, Advances in neural information processing systems 2018   [[Paper]](http://arxiv.org/abs/1810.02338)

- Teney, Damien; Liu, Lingqiao; Hengel, Anton van den, **Graph-Structured Representations for Visual Question Answering**, Proceedings of the IEEE conference on computer vision and pattern recognition 2017   [[Paper]](http://arxiv.org/abs/1609.05600)

- Vedantam, Ramakrishna; Desai, Karan; Lee, Stefan; Rohrbach, Marcus; Batra, Dhruv; Parikh, Devi, **Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering**, arXiv:1902.07864 [cs, stat] 2019   [[Paper]](http://arxiv.org/abs/1902.07864)


#### Visual Reasoning
- Yang, Jianwei and Mao, Jiayuan and Wu, Jiajun and Parikh, Devi and Cox, David D. and Tenenbaum, Joshua B. and Gan, Chuang,**Object-{Centric} {Diagnosis} of {Visual} {Reasoning}**,arXiv:2012.11587 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11587)

- Hong, Xin and Lan, Yanyan and Pang, Liang and Guo, Jiafeng and Cheng, Xueqi,**Transformation {Driven} {Visual} {Reasoning}**,arXiv:2011.13160 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13160)

- Wang, Zhonghao and Yu, Mo and Wang, Kai and Xiong, Jinjun and Hwu, Wen-mei and Hasegawa-Johnson, Mark and Shi, Humphrey,**Interpretable {Visual} {Reasoning} via {Induced} {Symbolic} {Space}**,arXiv:2011.11603 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.11603)

- Marasoviƒá, Ana and Bhagavatula, Chandra and Park, Jae Sung and Bras, Ronan Le and Smith, Noah A. and Choi, Yejin,**Natural {Language} {Rationales} with {Full}-{Stack} {Visual} {Reasoning}: {From} {Pixels} to {Semantic} {Frames} to {Commonsense} {Graphs}**,arXiv:2010.07526 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.07526)

- Le, Thao Minh and Le, Vuong and Venkatesh, Svetha and Tran, Truyen,**Dynamic Language Binding in Relational Visual Reasoning**,arXiv preprint arXiv:2004.14603 2020 [[Paper]](http://arxiv.org/abs/2004.14603)

- Wu, Jialin; Mooney, Raymond J., **Self-Critical Reasoning for Robust Visual Question Answering**, Advances in Neural Information Processing Systems 2019   [[Paper]](http://arxiv.org/abs/1905.09998)

- Cadene, Remi; Ben-younes, Hedi; Cord, Matthieu; Thome, Nicolas, **MUREL: Multimodal Relational Reasoning for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2019   [[Paper]](http://arxiv.org/abs/1902.09487)

- Wu, Chenfei; Zhou, Yanzhao; Li, Gen; Duan, Nan; Tang, Duyu; Wang, Xiaojie, **Deep Reason: A Strong Baseline for Real-World Visual Reasoning**, arXiv:1905.10226   2019   [[Paper]](http://arxiv.org/abs/1905.10226)

- Cao, Qingxing; Liang, Xiaodan; Li, Bailing; Li, Guanbin; Lin, Liang, **Visual Question Reasoning on General Dependency Tree**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](https://arxiv.org/abs/1804.00105v1)

- Mascharka, David; Tran, Philip; Soklaski, Ryan; Majumdar, Arjun, **Transparency by Design: Closing the Gap Between Performance and Interpretability in Visual Reasoning**, Proceedings of the IEEE conference on computer vision and pattern recognition 2018   [[Paper]](https://arxiv.org/abs/1803.05268v2)

- Desta, Mikyas T.; Chen, Larry; Kornuta, Tomasz, **Object-based reasoning in VQA**, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV 2018   [[Paper]](https://arxiv.org/abs/1801.09718v1)

- Wu, Chenfei; Liu, Jinlai; Wang, Xiaojie; Dong, Xuan, **Chain of Reasoning for Visual Question Answering**, Advances in Neural Information Processing Systems 31 2018   [[Paper]](http://papers.nips.cc/paper/7311-chain-of-reasoning-for-visual-question-answering.pdf)



- Aditya, Somak; Yang, Yezhou; Baral, Chitta, **Explicit Reasoning over End-to-End Neural Architectures for Visual Question Answering**, Thirty-Second AAAI Conference on Artificial Intelligence 2018   [[Paper]](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16446)

- Perez, Ethan; Strub, Florian; de Vries, Harm; Dumoulin, Vincent; Courville, Aaron, **FiLM: Visual Reasoning with a General Conditioning Layer**, Thirty-Second AAAI Conference on Artificial Intelligence 2017   [[Paper]](http://arxiv.org/abs/1709.07871)

- Hu, Ronghang; Andreas, Jacob; Rohrbach, Marcus; Darrell, Trevor; Saenko, Kate, **Learning to Reason: End-to-End Module Networks for Visual Question Answering**, Proceedings of the IEEE International Conference on Computer Vision 2017   [[Paper]](http://arxiv.org/abs/1704.05526)

- Santoro, Adam; Raposo, David; Barrett, David G. T.; Malinowski, Mateusz; Pascanu, Razvan; Battaglia, Peter; Lillicrap, Timothy, **A simple neural network module for relational reasoning**, Advances in neural information processing systems 2017   [[Paper]](http://arxiv.org/abs/1706.01427)

- Jang, Yunseok and Song, Yale and Yu, Youngjae and Kim, Youngjin and Kim, Gunhee,**{TGIF}-{QA}: {Toward} {Spatio}-{Temporal} {Reasoning} in {Visual} {Question} {Answering}**,Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2017 [[Paper]](http://openaccess.thecvf.com/content_cvpr_2017/html/Jang_TGIF-QA_Toward_Spatio-Temporal_CVPR_2017_paper.html)

- Johnson, Justin; Hariharan, Bharath; van der Maaten, Laurens; Hoffman, Judy; Fei-Fei, Li; Zitnick, C. Lawrence; Girshick, Ross, **Inferring and Executing Programs for Visual Reasoning**, Proceedings of the IEEE International Conference on Computer Vision 2017   [[Paper]](http://arxiv.org/abs/1705.03633)


#### Representation
- Zhang, Pengchuan and Li, Xiujun and Hu, Xiaowei and Yang, Jianwei and Zhang, Lei and Wang, Lijuan and Choi, Yejin and Gao, Jianfeng,**{VinVL}: {Making} {Visual} {Representations} {Matter} in {Vision}-{Language} {Models}**,arXiv:2101.00529 [cs] 2021 [[Paper]](http://arxiv.org/abs/2101.00529)

- Li, Wei and Gao, Can and Niu, Guocheng and Xiao, Xinyan and Liu, Hao and Liu, Jiachen and Wu, Hua and Wang, Haifeng,**{UNIMO}: {Towards} {Unified}-{Modal} {Understanding} and {Generation} via {Cross}-{Modal} {Contrastive} {Learning}**,arXiv:2012.15409 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.15409)
 
- Parcalabescu, Letitia and Gatt, Albert and Frank, Anette and Calixto, Iacer,**Seeing past words: {Testing} the cross-modal capabilities of pretrained {V}\&{L} models**,arXiv:2012.12352 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.12352)

- Gard√®res, Fran√ßois and Ziaeefard, Maryam and Abeloos, Baptiste and Lecue, Freddy,**{ConceptBert}: {Concept}-{Aware} {Representation} for {Visual} {Question} {Answering}**,Findings of the Association for Computational Linguistics:EMNLP 2020 2020 [[Paper]](https://www.aclweb.org/anthology/2020.findings-emnlp.44)

- Wang, Jianfeng and Hu, Xiaowei and Zhang, Pengchuan and Li, Xiujun and Wang, Lijuan and Zhang, Lei and Gao, Jianfeng and Liu, Zicheng,**{MiniVLM}: {A} {Smaller} and {Faster} {Vision}-{Language} {Model}**,arXiv:2012.06946 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.06946)

- Li, Linjie and Gan, Zhe and Liu, Jingjing,**A {Closer} {Look} at the {Robustness} of {Vision}-and-{Language} {Pre}-trained {Models}**,arXiv:2012.08673 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.08673)

- Bugliarello, Emanuele and Cotterell, Ryan and Okazaki, Naoaki and Elliott, Desmond,**Multimodal {Pretraining} {Unmasked}: {Unifying} the {Vision} and {Language} {BERTs}**,arXiv:2011.15124 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.15124)

- Khan, Aisha Urooj and Mazaheri, Amir and Lobo, Niels da Vitoria and Shah, Mubarak,**{MMFT}-{BERT}: {Multimodal} {Fusion} {Transformer} with {BERT} {Encodings} for {Visual} {Question} {Answering}**,arXiv:2010.14095 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.14095)

- Cho, Jaemin and Lu, Jiasen and Schwenk, Dustin and Hajishirzi, Hannaneh and Kembhavi, Aniruddha,**X-{LXMERT}: {Paint}, {Caption} and {Answer} {Questions} with {Multi}-{Modal} {Transformers}**,arXiv:2009.11278 [cs] 2020 [[Paper]](http://arxiv.org/abs/2009.11278)

- Shi, Lei and Shuang, Kai and Geng, Shijie and Su, Peng and Jiang, Zhengkai and Gao, Peng and Fu, Zuohui and de Melo, Gerard and Su, Sen,**Contrastive Visual-Linguistic Pretraining**,arXiv preprint arXiv:2007.13135 2020 [[Paper]](http://arxiv.org/abs/2007.13135)

- Li, Xiujun; Yin, Xi; Li, Chunyuan; Zhang, Pengchuan; Hu, Xiaowei; Zhang, Lei; Wang, Lijuan; Hu, Houdong; Dong, Li; Wei, Furu; Choi, Yejin; Gao, Jianfeng, **Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks**, arXiv:2004.06165   2020   [[Paper]](http://arxiv.org/abs/2004.06165)

- Yu, Fei; Tang, Jiji; Yin, Weichong; Sun, Yu; Tian, Hao; Wu, Hua; Wang, Haifeng, **ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph**, arXiv:2006.16934   2020   [[Paper]](http://arxiv.org/abs/2006.16934)

- Gan, Zhe; Chen, Yen-Chun; Li, Linjie; Zhu, Chen; Cheng, Yu; Liu, Jingjing, **Large-Scale Adversarial Training for Vision-and-Language Representation Learning**, arXiv:2006.06195   2020   [[Paper]](http://arxiv.org/abs/2006.06195)

- Huang, Haoyang; Su, Lin; Qi, Di; Duan, Nan; Cui, Edward; Bharti, Taroon; Zhang, Lei; Wang, Lijuan; Gao, Jianfeng; Liu, Bei; Fu, Jianlong; Zhang, Dongdong; Liu, Xin; Zhou, Ming, **M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training**, arXiv:2006.02635   2020   [[Paper]](http://arxiv.org/abs/2006.02635)

- Chen, Yen-Chun; Li, Linjie; Yu, Licheng; Kholy, Ahmed El; Ahmed, Faisal; Gan, Zhe; Cheng, Yu; Liu, Jingjing, **UNITER: UNiversal Image-TExt Representation Learning**, arXiv:1909.11740   2020   [[Paper]](http://arxiv.org/abs/1909.11740)

- Su, Weijie; Zhu, Xizhou; Cao, Yue; Li, Bin; Lu, Lewei; Wei, Furu; Dai, Jifeng, **VL-BERT: Pre-training of Generic Visual-Linguistic Representations**, arXiv:1908.08530   2020   [[Paper]](http://arxiv.org/abs/1908.08530)

- Lu, Jiasen; Goswami, Vedanuj; Rohrbach, Marcus; Parikh, Devi; Lee, Stefan, **12-in-1: Multi-Task Vision and Language Representation Learning**, CVPR 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Lu_12-in-1_Multi-Task_Vision_and_Language_Representation_Learning_CVPR_2020_paper.pdf)

- Lu, Jiasen; Batra, Dhruv; Parikh, Devi; Lee, Stefan, **ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks**, Advances in Neural Information Processing Systems 2019   [[Paper]](http://papers.nips.cc/paper/8297-vilbert-pretraining-task-agnostic-visiolinguistic-representations-for-vision-and-language-tasks.pdf)

- Zhou, Luowei; Palangi, Hamid; Zhang, Lei; Hu, Houdong; Corso, Jason J.; Gao, Jianfeng, **Unified Vision-Language Pre-Training for Image Captioning and VQA**, AAAI 2019   [[Paper]](http://arxiv.org/abs/1909.11059)


#### Diagnosis Method
- Zhu, Xi and Mao, Zhendong and Liu, Chunxiao and Zhang, Peng and Wang, Bin and Zhang, Yongdong,**Overcoming {Language} {Priors} with {Self}-supervised {Learning} for {Visual} {Question} {Answering}**,IJCAI 2020 [[Paper]](http://arxiv.org/abs/2012.11528)

- Winterbottom, Thomas and Xiao, Sarah and McLean, Alistair and Moubayed, Noura Al,**On {Modality} {Bias} in the {TVQA} {Dataset}**,BMVC 2020 [[Paper]](http://arxiv.org/abs/2012.10210)

- Whitehead, Spencer and Wu, Hui and Fung, Yi Ren and Ji, Heng and Feris, Rogerio and Saenko, Kate,**Learning from {Lexical} {Perturbations} for {Consistent} {Visual} {Question} {Answering}**,arXiv:2011.13406 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13406)

- Le-Ngo, Anh-Cat and Tran, Truyen and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha,**Logically {Consistent} {Loss} for {Visual} {Question} {Answering}**,arXiv:2011.10094 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.10094)

- Guo, Yangyang and Nie, Liqiang and Cheng, Zhiyong and Tian, Qi,**Loss-rescaling {VQA}: {Revisiting} {Language} {Prior} {Problem} from a {Class}-imbalance {View}**,arXiv:2010.16010 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.16010)

- Dua, Radhika and Kancheti, Sai Srinivas and Balasubramanian, Vineeth N.,**Beyond {VQA}: {Generating} {Multi}-word {Answer} and {Rationale} to {Visual} {Questions}**,arXiv:2010.11997 [cs] 2020 [[Paper]](https://arxiv.org/abs/2010.12852v1)

- Dharur, Sameer and Tendulkar, Purva and Batra, Dhruv and Parikh, Devi and Selvaraju, Ramprasaath R.,**{SOrT}-ing {VQA} {Models} : {Contrastive} {Gradient} {Learning} for {Improved} {Consistency}**,arXiv:2010.10038 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.10038)

- Huang, Hantao and Han, Tao and Han, Wei and Yap, Deep and Chiang, Cheng-Ming,**Answer-checking in {Context}: {A} {Multi}-modal {FullyAttention} {Network} for {Visual} {Question} {Answering}**,arXiv:2010.08708 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.08708)

- Kant, Yash and Moudgil, Abhinav and Batra, Dhruv and Parikh, Devi and Agrawal, Harsh,**Contrast and {Classify}: {Alternate} {Training} for {Robust} {VQA}**,arXiv:2010.06087 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.06087)

- Han, Wei and Huang, Hantao and Han, Tao,**Finding the {Evidence}: {Localization}-aware {Answer} {Prediction} for {Text} {Visual} {Question} {Answering}**,arXiv:2010.02582 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.02582)

- Gokhale, Tejas and Banerjee, Pratyay and Baral, Chitta and Yang, Yezhou,**{MUTANT}: {A} {Training} {Paradigm} for {Out}-of-{Distribution} {Generalization} in {Visual} {Question} {Answering}**,arXiv:2009.08566 [cs] 2020 [[Paper]](http://arxiv.org/abs/2009.08566)

- Do, Tuong and Nguyen, Binh X. and Tran, Huy and Tjiputra, Erman and Tran, Quang D. and Do, Thanh-Toan,**Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering**,arXiv:2009.11118 [cs] 2020 [[Paper]](http://arxiv.org/abs/2009.11118)

- Long, Yu and Tang, Pengjie and Wei, Zhihua and Gu, Jinjing and Wang, Hanli,**{RepeatPadding}: {Balancing} words and sentence length for language comprehension in visual question answering**,Information Sciences 2020 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S002002552030342X)

- Liu, Feng and Xiang, Tao and Hospedales, Timothy M. and Yang, Wankou and Sun, Changyin,**Inverse {Visual} {Question} {Answering}**,IEEE Transactions on Pattern Analysis and Machine Intelligence 2020 [[Paper]](https://ieeexplore.ieee.org/document/8528867/)

- Halbe, Shaunak, **Exploring Weaknesses of VQA Models through Attribution Driven Insights**, arXiv:2006.06637   2020   [[Paper]](http://arxiv.org/abs/2006.06637)

- Grand, Gabriel; Belinkov, Yonatan, **Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects**, arXiv:1906.08430 [cs, stat] 2019   [[Paper]](http://arxiv.org/abs/1906.08430)

- KV, Gouthaman; Mittal, Anurag, **Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder**, arXiv:2007.06198   2020   [[Paper]](http://arxiv.org/abs/2007.06198)

- Alipour, Kamran; Ray, Arijit; Lin, Xiao; Schulze, Jurgen P.; Yao, Yi; Burachas, Giedrius T., **The Impact of Explanations on AI Competency Prediction in VQA**, arXiv:2007.00900   2020   [[Paper]](http://arxiv.org/abs/2007.00900)

- Terao, Kento; Tamaki, Toru; Raytchev, Bisser; Kaneda, Kazufumi; Satoh, Shun'ichi, **Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions**, arXiv:2004.05595   2020   [[Paper]](http://arxiv.org/abs/2004.05595)

- Shrestha, Robik; Kafle, Kushal; Kanan, Christopher, **A negative case analysis of visual grounding methods for VQA**, arXiv:2004.05704   2020   [[Paper]](http://arxiv.org/abs/2004.05704)

- Abbasnejad, Ehsan; Teney, Damien; Parvaneh, Amin; Shi, Javen, **Counterfactual Vision and Language Learning**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition nan. [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Abbasnejad_Counterfactual_Vision_and_Language_Learning_CVPR_2020_paper.pdf)

- Jolly, Shailza; Palacio, Sebastian; Folz, Joachim; Raue, Federico; Hees, Joern; Dengel, Andreas, **P $\approx$ NP, at least in Visual Question Answering**, arXiv:2003.11844   2020   [[Paper]](http://arxiv.org/abs/2003.11844)

- Shevchenko, Violetta; Teney, Damien; Dick, Anthony; Hengel, Anton van den, **Visual Question Answering with Prior Class Semantics**, arXiv:2005.01239   2020   [[Paper]](http://arxiv.org/abs/2005.01239)


- Kolling, Camila; Wehrmann, J√¥natas; Barros, Rodrigo C., **Component Analysis for Visual Question Answering Architectures**, arXiv:2002.05104   2020   [[Paper]](http://arxiv.org/abs/2002.05104)

- van Steenkiste, Sjoerd; Locatello, Francesco; Schmidhuber, J√ºrgen; Bachem, Olivier, **Are Disentangled Representations Helpful for Abstract Visual Reasoning?**, Advances in Neural Information Processing Systems 2019   [[Paper]](http://arxiv.org/abs/1905.12506)

- Cao, Qingxing and Liang, Xiaodan and Li, Bailin and Lin, Liang,**Interpretable {Visual} {Question} {Answering} by {Reasoning} on {Dependency} {Trees}**,IEEE Transactions on Pattern Analysis and Machine Intelligence 2019 [[Paper]](https://ieeexplore.ieee.org/document/8847465/)

- Selvaraju, Ramprasaath R.; Lee, Stefan; Shen, Yilin; Jin, Hongxia; Ghosh, Shalini; Heck, Larry; Batra, Dhruv; Parikh, Devi, **Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded**, Proceedings of the IEEE International Conference on Computer Vision 2019   [[Paper]](http://arxiv.org/abs/1902.03751)

- Huang, Jia-Hong; Alfadly, Modar; Ghanem, Bernard; Worring, Marcel, **Assessing the Robustness of Visual Question Answering**, arXiv:1912.01452   2019   [[Paper]](http://arxiv.org/abs/1912.01452)

- Cadene, Remi; Dancette, Corentin; Ben-younes, Hedi; Cord, Matthieu; Parikh, Devi, **RUBi: Reducing Unimodal Biases in Visual Question Answering**, Advances in neural information processing systems 2019   [[Paper]](http://arxiv.org/abs/1906.10169)

- Pahuja, Vardaan; Fu, Jie; Pal, Christopher J., **Learning Sparse Mixture of Experts for Visual Question Answering**, arXiv:1909.09192 [cs, stat] 2019   [[Paper]](http://arxiv.org/abs/1909.09192)

- Kuhnle, Alexander; Xie, Huiyuan; Copestake, Ann A., **How clever is the FiLM model, and how clever can it be?**, Proceedings of the European Conference on Computer Vision (ECCV) 2018   [[Paper]](http://openaccess.thecvf.com/content_ECCVW_2018/papers/11132/Kuhnle_How_clever_is_the_FiLM_model_and_how_clever_can_ECCVW_2018_paper.pdf)

- Park, Dong Huk; Hendricks, Lisa Anne; Akata, Zeynep; Rohrbach, Anna; Schiele, Bernt; Darrell, Trevor; Rohrbach, Marcus, **Multimodal Explanations: Justifying Decisions and Pointing to the Evidence**, arXiv:1802.08129   2018   [[Paper]](http://arxiv.org/abs/1802.08129)

- Prabhakar, Prakruthi; Kulkarni, Nitish; Zhang, Linghao, **Question Relevance in Visual Question Answering**, arXiv:1807.08435   2018   [[Paper]](http://arxiv.org/abs/1807.08435)

- Agrawal, Aishwarya; Batra, Dhruv; Parikh, Devi; Kembhavi, Aniruddha, **Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1712.00377)



- Manjunatha, Varun; Saini, Nirat; Davis, Larry S., **Explicit Bias Discovery in Visual Question Answering Models**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1811.07789)


- Chao, Wei-Lun; Hu, Hexiang; Sha, Fei, **Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets**, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) 2018   [[Paper]](https://www.aclweb.org/anthology/N18-1040)

- Malinowski, Mateusz; Doersch, Carl, **The Visual QA Devil in the Details: The Impact of Early Fusion and Batch Norm on CLEVR**, arXiv:1809.04482   2018   [[Paper]](http://arxiv.org/abs/1809.04482)

- Ramakrishnan, Santhosh K.; Pal, Ambar; Sharma, Gaurav; Mittal, Anurag, **An Empirical Evaluation of Visual Question Answering for Novel Objects**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2017   [[Paper]](http://arxiv.org/abs/1704.02516)

- Kafle, Kushal; Yousefhussien, Mohammed; Kanan, Christopher, **Data Augmentation for Visual Question Answering**, Proceedings of the 10th International Conference on Natural Language Generation 2017   [[Paper]](https://www.aclweb.org/anthology/W17-3529)

- Qiao, Tingting; Dong, Jianfeng; Xu, Duanqing, **Exploring Human-like Attention Supervision in Visual Question Answering**, Thirty-Second AAAI Conference on Artificial Intelligence 2017   [[Paper]](http://arxiv.org/abs/1709.06308)

- Huang, Jia-Hong; Dao, Cuong Duc; Alfadly, Modar; Ghanem, Bernard, **A Novel Framework for Robustness Analysis of Visual QA Models**, Proceedings of the AAAI Conference on Artificial Intelligence 2017   [[Paper]](http://arxiv.org/abs/1711.06232)

- Selvaraju, Ramprasaath R.; Cogswell, Michael; Das, Abhishek; Vedantam, Ramakrishna; Parikh, Devi; Batra, Dhruv, **Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization**, 2017 IEEE International Conference on Computer Vision (ICCV) 2017   [[Paper]](http://ieeexplore.ieee.org/document/8237336/)

- Huang, Jia-Hong; Alfadly, Modar; Ghanem, Bernard, **Robustness Analysis of Visual QA Models by Basic Questions**, ArXiv 2017   [[Paper]](https://arxiv.org/pdf/1709.04625)

- Kafle, Kushal; Kanan, Christopher, **An Analysis of Visual Question Answering Algorithms**, Proceedings of the IEEE International Conference on Computer Vision 2017   [[Paper]](http://openaccess.thecvf.com/content_ICCV_2017/papers/Kafle_An_Analysis_of_ICCV_2017_paper.pdf)

- Ray, Arijit; Christie, Gordon; Bansal, Mohit; Batra, Dhruv; Parikh, Devi, **Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions**, Proceedings of the 2016 Conference on Empirical Methods in Natural           Language Processing 2016   [[Paper]](http://aclweb.org/anthology/D16-1090)

- Agrawal, Aishwarya; Batra, Dhruv; Parikh, Devi, **Analyzing the Behavior of Visual Question Answering Models**, narXiv:1606.07356 2016   [[Paper]](http://www.researchgate.net/publication/304352594_Analyzing_the_Behavior_of_Visual_Question_Answering_Models)

- Das, Abhishek; Agrawal, Harsh; Zitnick, C. Lawrence; Parikh, Devi; Batra, Dhruv, **Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions?**, Computer Vision and Image Understanding 2016   [[Paper]](http://arxiv.org/abs/1606.03556)

- Goyal, Yash; Mohapatra, Akrit; Parikh, Devi; Batra, Dhruv, **Towards Transparent AI Systems: Interpreting Visual Question Answering Models**, arXiv:1608.08974   2016   [[Paper]](http://arxiv.org/abs/1608.08974)

- Jabri, Allan; Joulin, Armand; van der Maaten, Laurens, **Revisiting Visual Question Answering Baselines**, European conference on computer vision 2016   [[Paper]](https://arxiv.org/abs/1606.08390v2)

- Zhang, Peng; Goyal, Yash; Summers-Stay, Douglas; Batra, Dhruv; Parikh, Devi, **Yin and Yang: Balancing and Answering Binary Visual Questions**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2015   [[Paper]](http://arxiv.org/abs/1511.05099)

- Wu, Qi; Shen, Chunhua; Liu, Lingqiao; Dick, Anthony; Hengel, Anton van den, **What value do explicit high level concepts have in vision to language problems?**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1506.01144)

- Agarwal, Vedika; Shetty, Rakshith; Fritz, Mario, **Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Agarwal_Towards_Causal_VQA_Revealing_and_Reducing_Spurious_Correlations_by_Invariant_CVPR_2020_paper.pdf)

- Selvaraju, Ramprasaath R; Tendulkar, Purva; Parikh, Devi; Horvitz, Eric; Ribeiro, Marco Tulio; Nushi, Besmira; Kamar, Ece, **SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Selvaraju_SQuINTing_at_VQA_Models_Introspecting_VQA_Models_With_Sub-Questions_CVPR_2020_paper.pdf)

#### 
- Dognin, Pierre and Melnyk, Igor and Mroueh, Youssef and Padhi, Inkit and Rigotti, Mattia and Ross, Jarret and Schiff, Yair and Young, Richard A. and Belgodere, Brian,**Image {Captioning} as an {Assistive} {Technology}: {Lessons} {Learned} from {VizWiz} 2020 {Challenge}**,arXiv:2012.11696 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.11696)

- Chen, Long and Yan, Xin and Xiao, Jun and Zhang, Hanwang and Pu, Shiliang and Zhuang, Yueting,**Counterfactual {Samples} {Synthesizing} for {Robust} {Visual} {Question} {Answering}**,IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2020 [[Paper]](https://ieeexplore.ieee.org/document/9157377/)

- Banerjee, Pratyay and Gokhale, Tejas and Yang, Yezhou and Baral, Chitta,**Self-{Supervised} {VQA}: {Answering} {Visual} {Questions} using {Images} and {Captions}**,arXiv:2012.02356 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.02356)

- Patel, Alkesh and Bindal, Akanksha and Kotek, Hadas and Klein, Christopher and Williams, Jason,**Generating {Natural} {Questions} from {Images} for {Multimodal} {Assistants}**,arXiv:2012.03678 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.03678)

- Yang, Zhengyuan and Lu, Yijuan and Wang, Jianfeng and Yin, Xi and Florencio, Dinei and Wang, Lijuan and Zhang, Cha and Zhang, Lei and Luo, Jiebo,**{TAP}: {Text}-{Aware} {Pre}-training for {Text}-{VQA} and {Text}-{Caption}**,arXiv:2012.04638 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.04638)

- Zhu, Qi and Gao, Chenyu and Wang, Peng and Wu, Qi,**Simple is not {Easy}: {A} {Simple} {Strong} {Baseline} for {TextVQA} and {TextCaps}**,arXiv:2012.05153 [cs] 2020 [[Paper]](http://arxiv.org/abs/2012.05153)

- Mani, Arjun and Hinthorn, Will and Yoo, Nobline and Russakovsky, Olga,**Point and {Ask}: {Incorporating} {Pointing} into {Visual} {Question} {Answering}**,arXiv:2011.13681 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.13681)

- Ma, Jie and Liu, Jun and Li, Junjun and Zheng, Qinghua and Yin, Qingyu and Zhou, Jianlong and Huang, Yi,**{XTQA}: {Span}-{Level} {Explanations} of the {Textbook} {Question} {Answering}**,arXiv:2011.12662 [cs] 2020 [[Paper]](http://arxiv.org/abs/2011.12662)

- Frolov, Stanislav and Jolly, Shailza and Hees, J√∂rn and Dengel, Andreas,**Leveraging {Visual} {Question} {Answering} to {Improve} {Text}-to-{Image} {Synthesis}**,arXiv:2010.14953 [cs] 2020 [[Paper]](http://arxiv.org/abs/2010.14953)

- Liu, Yun and Zhang, Xiaoming and Huang, Feiran and Zhou, Zhibo and Zhao, Zhonghua and Li, Zhoujun,**Visual {Question} {Answering} via {Combining} {Inferential} {Attention} and {Semantic} {Space} {Mapping}**,Knowledge-Based Systems 2020 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S0950705120304962)

- Hong, Jongkwang and Park, Sungho and Byun, Hyeran,**Selective residual learning for {Visual} {Question} {Answering}**,Neurocomputing 2020 [[Paper]](https://linkinghub.elsevier.com/retrieve/pii/S0925231220304859)

- Bansal, Ankan and Zhang, Yuting and Chellappa, Rama,**Visual Question Answering on Image Sets**,arXiv preprint arXiv:2008.11976 2020 [[Paper]](http://arxiv.org/abs/2008.11976)

- Tang, Ruixue and Ma, Chao and Zhang, Wei Emma and Wu, Qi and Yang, Xiaokang, **Semantic Equivalent Adversarial Data Augmentation for Visual Question Answering**, arXiv:2007.09592 2020 [[Paper]](http://arxiv.org/abs/2007.09592)

- Goel, Vatsal; Chandak, Mohit; Anand, Ashish; Guha, Prithwijit, **IQ-VQA: Intelligent Visual Question Answering**, arXiv:2007.04422   2020   [[Paper]](http://arxiv.org/abs/2007.04422)

- Xiong, Peixi; Wu, Ying, **TA-Student VQA: Multi-Agents Training by Self-Questioning**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Xiong_TA-Student_VQA_Multi-Agents_Training_by_Self-Questioning_CVPR_2020_paper.pdf)

- Pollard, Amelia Elizabeth; Shapiro, Jonathan L., **Visual Question Answering as a Multi-Task Problem**, arXiv:2007.01780   2020   [[Paper]](http://arxiv.org/abs/2007.01780)

- Dancette, Corentin; Cadene, Remi; Chen, Xinlei; Cord, Matthieu, **Overcoming Statistical Shortcuts for Open-ended Visual Counting**, arXiv:2006.10079 [cs, eess] 2020   [[Paper]](http://arxiv.org/abs/2006.10079)

- Yu, Zhou; Cui, Yuhao; Yu, Jun; Wang, Meng; Tao, Dacheng; Tian, Qi, **Deep Multimodal Neural Architecture Search**, arXiv:2004.12070   2020   [[Paper]](http://arxiv.org/abs/2004.12070)

- Chen, Long; Yan, Xin; Xiao, Jun; Zhang, Hanwang; Pu, Shiliang; Zhuang, Yueting, **Counterfactual Samples Synthesizing for Robust Visual Question Answering**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://arxiv.org/abs/2003.06576)

- He, Xuehai; Zhang, Yichen; Mou, Luntian; Xing, Eric; Xie, Pengtao, **PathVQA: 30000+ Questions for Medical Visual Question Answering**, arXiv:2003.10286   2020   [[Paper]](http://arxiv.org/abs/2003.10286)

- Ren, Fuji; Zhou, Yangyang, **CGMVQA: A New Classification and Generative Model for Medical Visual Question Answering**, IEEE Access 2020   [[Paper]](https://ieeexplore.ieee.org/iel7/6287639/8948470/09032109.pdf)

- Li, Hui; Wang, Peng; Shen, Chunhua; Hengel, Anton van den, **Visual Question Answering as Reading Comprehension**, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2019   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Visual_Question_Answering_as_Reading_Comprehension_CVPR_2019_paper.pdf)

- Patro, Badri N.; Kumar, Sandeep; Kurmi, Vinod K.; Namboodiri, Vinay P., **Multimodal Differential Network for Visual Question Generation**, arXiv:1808.03986   2019   [[Paper]](http://arxiv.org/abs/1808.03986)

- Ruwa, Nelson and Mao, Qirong and Wang, Liangjun and Gou, Jianping and Dong, Ming,**Mood-aware visual question answering**,Neurocomputing 2019 [[Paper]](http://www.sciencedirect.com/science/article/pii/S0925231218313808)

- Toor, Andeep S. and Wechsler, Harry and Nappi, Michele,**Question action relevance and editing for visual question answering**,Multimedia Tools and Applications 2019 [[Paper]](http://link.springer.com/10.1007/s11042-018-6097-z)

- Lu, Jiaying; Ye, Xin; Ren, Yi; Yang, Yezhou, **Good, Better, Best: Textual Distractors Generation for Multi-Choice VQA via Policy Gradient**, arXiv:1910.09134   2019   [[Paper]](http://arxiv.org/abs/1910.09134)

- Greco, Claudio; Plank, Barbara; Fern√°ndez, Raquel; Bernardi, Raffaella, **PsyPsycholinguistics meets Continual Learning: Measuring Catastrophic Forgetting in Visual Question Answering**, arXiv:1906.04229   2019   [[Paper]](http://arxiv.org/abs/1906.04229)

- Kafle, Kushal; Kanan, Christopher, **Answer Them All! Toward Universal Visual Question Answering Models**, Proceedings of the IEEE conference on computer vision and pattern recognition 2019   [[Paper]](http://arxiv.org/abs/1903.00366)

- Sharma, Monika; Gupta, Shikha; Chowdhury, Arindam; Vig, Lovekesh, **ChartNet: Visual Reasoning over Statistical Charts using MAC-Networks**, 2019 International Joint Conference on Neural Networks (IJCNN) 2019   [[Paper]](https://ieeexplore.ieee.org/document/8852427/)

- Dong, Xuanyi; Zhu, Linchao; Zhang, De; Yang, Yi; Wu, Fei, **Fast Parameter Adaptation for Few-shot Image Captioning and Visual Question Answering**, ACM Multimedia 2018   [[Paper]](https://dl.acm.org/doi/abs/10.1145/3240508.3240527)

- Hu, Hexiang; Chao, Wei-Lun; Sha, Fei, **Learning Answer Embeddings for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2018   [[Paper]](http://arxiv.org/abs/1806.03724)

- Goyal, Ankit; Wang, Jian; Deng, Jia, **Think Visually: Question Answering through Virtual Imagery**, arXiv:1805.11025   2018   [[Paper]](http://arxiv.org/abs/1805.11025)

- Wang, Zhe; Liu, Xiaoyi; Wang, Limin; Qiao, Yu; Xie, Xiaohui; Fowlkes, Charless, **Structured Triplet Learning with POS-Tag Guided Attention for Visual Question Answering**, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV) 2018   [[Paper]](https://ieeexplore.ieee.org/document/8354313/)

- Fang, Zhiwei; Liu, Jing; Qiao, Yanyuan; Tang, Qu; Li, Yong; Lu, Hanqing, **Enhancing Visual Question Answering Using Dropout**, Proceedings of the 26th ACM international conference on Multimedia 2018   [[Paper]](https://doi.org/10.1145/3240508.3240662)

- Huang, Li-Chi; Kulkarni, Kuldeep; Jha, Anik; Lohit, Suhas; Jayasuriya, Suren; Turaga, Pavan, **CS-VQA: Visual Question Answering with Compressively Sensed Images**, 2018 25th IEEE International Conference on Image Processing (ICIP) 2018   [[Paper]](https://arxiv.org/abs/1806.03379v1)

- Li, Yuanpeng; Yang, Yi; Wang, Jianyu; Xu, Wei, **Zero-Shot Transfer VQA Dataset**, arXiv:1811.00692 2018   [[Paper]](https://arxiv.org/pdf/1811.00692)

- Gordon, Daniel; Kembhavi, Aniruddha; Rastegari, Mohammad; Redmon, Joseph; Fox, Dieter; Farhadi, Ali, **IQA: Visual Question Answering in Interactive Environments**, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition 2017   [[Paper]](http://openaccess.thecvf.com/content_cvpr_2018/papers/Gordon_IQA_Visual_Question_CVPR_2018_paper.pdf)


- Zhang, Junjie; Wu, Qi; Shen, Chunhua; Zhang, Jian; Lu, Jianfeng; Hengel, Anton van den, **Asking the Difficult Questions: Goal-Oriented Visual Question Generation via Intermediate Rewards**, arXiv:1711.07614   2017   [[Paper]](http://arxiv.org/abs/1711.07614)



- Liu, Feng; Xiang, Tao; Hospedales, Timothy M.; Yang, Wankou; Sun, Changyin, **iVQA: Inverse Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2017   [[Paper]](http://arxiv.org/abs/1710.03370)

- Teney, Damien; Anderson, Peter; He, Xiaodong; Hengel, Anton van den, **Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge**, Proceedings of the IEEE conference on computer vision and pattern recognition 2017   [[Paper]](http://arxiv.org/abs/1708.02711)

- Kafle, Kushal; Kanan, Christopher, **Answer-Type Prediction for Visual Question Answering**, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition 2016   [[Paper]](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Kafle_Answer-Type_Prediction_for_CVPR_2016_paper.pdf)

- Zitnick, C. Lawrence; Agrawal, Aishwarya; Antol, Stanislaw; Mitchell, Margaret; Batra, Dhruv; Parikh, Devi, **Measuring Machine Intelligence Through Visual Question Answering**, arXiv:1608.08716   2016   [[Paper]](http://arxiv.org/abs/1608.08716)

- Malinowski, Mateusz; Fritz, Mario, **Hard to Cheat: A Turing Test based on Answering Questions about Images**, arXiv:1501.03302   2015   [[Paper]](http://arxiv.org/abs/1501.03302)

- Noh, Hyeonwoo; Seo, Paul Hongsuck; Han, Bohyung, **Image Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction**, Proceedings of the IEEE conference on computer vision and pattern recognition 2015   [[Paper]](http://arxiv.org/abs/1511.05756)

- Li, Ruiyu; Jia, Jiaya, **Visual Question Answering with Question Representation Update (QRU)**, Advances in Neural Information Processing Systems 2016   [[Paper]](https://papers.nips.cc/paper/6261-visual-question-answering-with-question-representation-update-qru.pdf)

- Geman, Donald; Geman, Stuart; Hallonquist, Neil; Younes, Laurent, **Visual Turing test for computer vision systems**, Proceedings of the National Academy of Sciences 2015   [[Paper]](http://www.pnas.org/lookup/doi/10.1073/pnas.1422953112)

- Bigham, Jeffrey P.; Yeh, Tom; Jayant, Chandrika; Ji, Hanjie; Little, Greg; Miller, Andrew; Miller, Robert C.; Tatarowicz, Aubrey; White, Brandyn; White, Samuel, **VizWiz: nearly real-time answers to visual questions**, Proceedings of the 2010 International Cross Disciplinary Conference on Web Accessibility (W4A) - W4A '10 2010   [[Paper]](http://portal.acm.org/citation.cfm?doid=1805986.1806020)

- Malinowski, Mateusz; Fritz, Mario, **Towards a Visual Turing Challenge**, arXiv:1410.8027   2014   [[Paper]](http://arxiv.org/abs/1410.8027)

- Vatashsky, Ben-Zion; Ullman, Shimon, **VQA With No Questions-Answers Training**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Vatashsky_VQA_With_No_Questions-Answers_Training_CVPR_2020_paper.pdf)

- Wang, Xinyu; Liu, Yuliang; Shen, Chunhua; Ng, Chun Chet; Luo, Canjie; Jin, Lianwen; Chan, Chee Seng, **On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](nahttp://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_On_the_General_Value_of_Evidence_and_Bilingual_Scene-Text_Visual_CVPR_2020_paper.pdfn)

- Wang, Tan; Huang, Jianqiang; Zhang, Hanwang; Sun, Qianru, **Visual Commonsense R-CNN**, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020   [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_Visual_Commonsense_R-CNN_CVPR_2020_paper.pdf)


